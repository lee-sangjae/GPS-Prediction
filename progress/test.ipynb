{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'YT341':        latitude   longitude  velocity  direction  distance  dir_diff\n",
       " 0     35.109440  129.094971         0          0  0.000000       0.0\n",
       " 1     35.109440  129.094971         0          0  0.000000       0.0\n",
       " 2     35.109440  129.094971         0          0  0.000000       0.0\n",
       " 3     35.109440  129.094971         0          0  0.000000       0.0\n",
       " 4     35.109440  129.094971         0          0  0.000000       0.0\n",
       " ...         ...         ...       ...        ...       ...       ...\n",
       " 6663  35.107014  129.094391        18        353  5.092735       0.0\n",
       " 6664  35.107063  129.094376        18        352  5.688175      -1.0\n",
       " 6665  35.107109  129.094376        18        352  5.092735       0.0\n",
       " 6666  35.107155  129.094360        17        352  5.266368       0.0\n",
       " 6667  35.107197  129.094360        16        348  4.670193      -4.0\n",
       " \n",
       " [6668 rows x 6 columns],\n",
       " 'YT374':        latitude   longitude  velocity  direction  distance  dir_diff\n",
       " 0     35.098816  129.096527        22        176  1.278743       2.0\n",
       " 1     35.098759  129.096527        22        175  6.360359      -1.0\n",
       " 2     35.098702  129.096542        23        174  6.510885      -1.0\n",
       " 3     35.098644  129.096542        23        174  6.360359       0.0\n",
       " 4     35.098587  129.096558        23        174  6.519813       0.0\n",
       " ...         ...         ...       ...        ...       ...       ...\n",
       " 6664  35.105450  129.095383         0          0  0.000000       0.0\n",
       " 6665  35.105446  129.095383         0          0  0.422541       0.0\n",
       " 6666  35.105446  129.095383         0          0  0.000000       0.0\n",
       " 6667  35.105446  129.095383         0          0  0.000000       0.0\n",
       " 6668  35.105446  129.095383         0          0  0.000000       0.0\n",
       " \n",
       " [6669 rows x 6 columns],\n",
       " 'YT377':        latitude   longitude  velocity  direction  distance  dir_diff\n",
       " 0     35.105904  129.095886        11        174  2.546367       1.0\n",
       " 1     35.105866  129.095886        11        173  4.236533      -1.0\n",
       " 2     35.105846  129.095901        11        174  2.539244       1.0\n",
       " 3     35.105812  129.095901        11        175  3.813991       1.0\n",
       " 4     35.105789  129.095901        11        174  2.546367      -1.0\n",
       " ...         ...         ...       ...        ...       ...       ...\n",
       " 6664  35.107643  129.094192         7        354  1.690165      -1.0\n",
       " 6665  35.107662  129.094177         7        354  2.539227       0.0\n",
       " 6666  35.107681  129.094177         8        355  2.123826       1.0\n",
       " 6667  35.107708  129.094177         7        356  2.968909       1.0\n",
       " 6668  35.107723  129.094177         7        356  1.690165       0.0\n",
       " \n",
       " [6669 rows x 6 columns]}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evnt_dt\n",
       "2021-10-31 19:08:51+00:00         NaN\n",
       "2021-10-31 19:08:52+00:00    0.626758\n",
       "2021-10-31 19:08:53+00:00   -0.626758\n",
       "2021-10-31 19:08:54+00:00   -0.949253\n",
       "2021-10-31 19:08:55+00:00    0.949253\n",
       "                               ...   \n",
       "2021-10-31 20:59:55+00:00   -0.459672\n",
       "2021-10-31 20:59:56+00:00    0.000000\n",
       "2021-10-31 20:59:57+00:00    0.459672\n",
       "2021-10-31 20:59:58+00:00   -0.459723\n",
       "2021-10-31 20:59:59+00:00    0.000000\n",
       "Name: cos_dir, Length: 6669, dtype: float64"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp[\"cos_dir\"].shift(1)-tmp[\"cos_dir\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>velocity</th>\n",
       "      <th>direction</th>\n",
       "      <th>distance</th>\n",
       "      <th>dir_diff</th>\n",
       "      <th>sin_dir</th>\n",
       "      <th>cos_dir</th>\n",
       "      <th>cos_dir_diff</th>\n",
       "      <th>sin_dir_diff</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>evnt_dt</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:08:51+00:00</th>\n",
       "      <td>35.105904</td>\n",
       "      <td>129.095886</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>2.546367</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.936462</td>\n",
       "      <td>-0.350769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:08:52+00:00</th>\n",
       "      <td>35.105866</td>\n",
       "      <td>129.095886</td>\n",
       "      <td>11</td>\n",
       "      <td>173</td>\n",
       "      <td>4.236533</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.210811</td>\n",
       "      <td>-0.977527</td>\n",
       "      <td>0.626758</td>\n",
       "      <td>-0.725651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:08:53+00:00</th>\n",
       "      <td>35.105846</td>\n",
       "      <td>129.095901</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>2.539244</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.936462</td>\n",
       "      <td>-0.350769</td>\n",
       "      <td>-0.626758</td>\n",
       "      <td>0.725651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:08:54+00:00</th>\n",
       "      <td>35.105812</td>\n",
       "      <td>129.095901</td>\n",
       "      <td>11</td>\n",
       "      <td>175</td>\n",
       "      <td>3.813991</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.801135</td>\n",
       "      <td>0.598484</td>\n",
       "      <td>-0.949253</td>\n",
       "      <td>-0.135327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 19:08:55+00:00</th>\n",
       "      <td>35.105789</td>\n",
       "      <td>129.095901</td>\n",
       "      <td>11</td>\n",
       "      <td>174</td>\n",
       "      <td>2.546367</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-0.936462</td>\n",
       "      <td>-0.350769</td>\n",
       "      <td>0.949253</td>\n",
       "      <td>0.135327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:59:55+00:00</th>\n",
       "      <td>35.107643</td>\n",
       "      <td>129.094192</td>\n",
       "      <td>7</td>\n",
       "      <td>354</td>\n",
       "      <td>1.690165</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.841455</td>\n",
       "      <td>-0.540328</td>\n",
       "      <td>-0.459672</td>\n",
       "      <td>-0.841485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:59:56+00:00</th>\n",
       "      <td>35.107662</td>\n",
       "      <td>129.094177</td>\n",
       "      <td>7</td>\n",
       "      <td>354</td>\n",
       "      <td>2.539227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.841455</td>\n",
       "      <td>-0.540328</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:59:57+00:00</th>\n",
       "      <td>35.107681</td>\n",
       "      <td>129.094177</td>\n",
       "      <td>8</td>\n",
       "      <td>355</td>\n",
       "      <td>2.123826</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.459672</td>\n",
       "      <td>0.841485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:59:58+00:00</th>\n",
       "      <td>35.107708</td>\n",
       "      <td>129.094177</td>\n",
       "      <td>7</td>\n",
       "      <td>356</td>\n",
       "      <td>2.968909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.841487</td>\n",
       "      <td>-0.540277</td>\n",
       "      <td>-0.459723</td>\n",
       "      <td>0.841457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2021-10-31 20:59:59+00:00</th>\n",
       "      <td>35.107723</td>\n",
       "      <td>129.094177</td>\n",
       "      <td>7</td>\n",
       "      <td>356</td>\n",
       "      <td>1.690165</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.841487</td>\n",
       "      <td>-0.540277</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6669 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                            latitude   longitude  velocity  direction  \\\n",
       "evnt_dt                                                                 \n",
       "2021-10-31 19:08:51+00:00  35.105904  129.095886        11        174   \n",
       "2021-10-31 19:08:52+00:00  35.105866  129.095886        11        173   \n",
       "2021-10-31 19:08:53+00:00  35.105846  129.095901        11        174   \n",
       "2021-10-31 19:08:54+00:00  35.105812  129.095901        11        175   \n",
       "2021-10-31 19:08:55+00:00  35.105789  129.095901        11        174   \n",
       "...                              ...         ...       ...        ...   \n",
       "2021-10-31 20:59:55+00:00  35.107643  129.094192         7        354   \n",
       "2021-10-31 20:59:56+00:00  35.107662  129.094177         7        354   \n",
       "2021-10-31 20:59:57+00:00  35.107681  129.094177         8        355   \n",
       "2021-10-31 20:59:58+00:00  35.107708  129.094177         7        356   \n",
       "2021-10-31 20:59:59+00:00  35.107723  129.094177         7        356   \n",
       "\n",
       "                           distance  dir_diff   sin_dir   cos_dir  \\\n",
       "evnt_dt                                                             \n",
       "2021-10-31 19:08:51+00:00  2.546367       1.0 -0.936462 -0.350769   \n",
       "2021-10-31 19:08:52+00:00  4.236533      -1.0 -0.210811 -0.977527   \n",
       "2021-10-31 19:08:53+00:00  2.539244       1.0 -0.936462 -0.350769   \n",
       "2021-10-31 19:08:54+00:00  3.813991       1.0 -0.801135  0.598484   \n",
       "2021-10-31 19:08:55+00:00  2.546367      -1.0 -0.936462 -0.350769   \n",
       "...                             ...       ...       ...       ...   \n",
       "2021-10-31 20:59:55+00:00  1.690165      -1.0  0.841455 -0.540328   \n",
       "2021-10-31 20:59:56+00:00  2.539227       0.0  0.841455 -0.540328   \n",
       "2021-10-31 20:59:57+00:00  2.123826       1.0 -0.000030 -1.000000   \n",
       "2021-10-31 20:59:58+00:00  2.968909       1.0 -0.841487 -0.540277   \n",
       "2021-10-31 20:59:59+00:00  1.690165       0.0 -0.841487 -0.540277   \n",
       "\n",
       "                           cos_dir_diff  sin_dir_diff  \n",
       "evnt_dt                                                \n",
       "2021-10-31 19:08:51+00:00           NaN           NaN  \n",
       "2021-10-31 19:08:52+00:00      0.626758     -0.725651  \n",
       "2021-10-31 19:08:53+00:00     -0.626758      0.725651  \n",
       "2021-10-31 19:08:54+00:00     -0.949253     -0.135327  \n",
       "2021-10-31 19:08:55+00:00      0.949253      0.135327  \n",
       "...                                 ...           ...  \n",
       "2021-10-31 20:59:55+00:00     -0.459672     -0.841485  \n",
       "2021-10-31 20:59:56+00:00      0.000000      0.000000  \n",
       "2021-10-31 20:59:57+00:00      0.459672      0.841485  \n",
       "2021-10-31 20:59:58+00:00     -0.459723      0.841457  \n",
       "2021-10-31 20:59:59+00:00      0.000000      0.000000  \n",
       "\n",
       "[6669 rows x 10 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "tmp = data.copy()\n",
    "tmp[\"sin_dir\"] = tmp[\"direction\"].apply(math.sin)\n",
    "tmp[\"cos_dir\"] = tmp[\"direction\"].apply(math.cos)\n",
    "tmp[\"cos_dir_diff\"] = tmp[\"cos_dir\"].shift(1)-tmp[\"cos_dir\"]\n",
    "tmp[\"sin_dir_diff\"] = tmp[\"sin_dir\"].shift(1)-tmp[\"sin_dir\"]\n",
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "executed type : train equ_no : YT301 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT303 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT308 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT312 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT313 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT324 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT340 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT343 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT366 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT375 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT389 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT391 dropna(subset=distance) count : 1\n",
      "executed type : train equ_no : YT396 dropna(subset=distance) count : 1\n",
      "executed type : test equ_no : YT341 dropna(subset=distance) count : 1\n",
      "executed type : test equ_no : YT374 dropna(subset=distance) count : 1\n",
      "executed type : test equ_no : YT377 dropna(subset=distance) count : 1\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Apr 12 13:18:10 2022\n",
    "\n",
    "@author: USER\n",
    "\"\"\"\n",
    "\n",
    "import os, glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "# import torchvision #\n",
    "# import torchvision.datasets as dset\n",
    "import torchvision.transforms as tr #데이터 불러오면서 전처리를 가능한게 해주는 라이브러리 \n",
    "from torch.utils.data import TensorDataset,DataLoader, Dataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts\n",
    "from torch.autograd import Variable \n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from haversine import haversine\n",
    "\n",
    "import argparse\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from src import preprocess as pp\n",
    "from src import model\n",
    "# from src import data\n",
    "\n",
    "import config\n",
    "\n",
    "train_data_paths=glob.glob(os.path.join(config.BASE_DIR, f\"data\\\\train\\\\*.csv\"))\n",
    "test_data_paths=glob.glob(os.path.join(config.BASE_DIR, f\"data\\\\test\\\\*.csv\"))\n",
    "\n",
    "# train_data = pd.concat([pd.read_csv(tr_data) for tr_data in train_data_paths]) \n",
    "# test_data = pd.concat([pd.read_csv(ts_data) for ts_data in test_data_paths]) \n",
    "# print(train_data.shape, test_data.shape)\n",
    "import math\n",
    "\n",
    "train_dict, test_dict={},{}\n",
    "total_data_paths = train_data_paths.copy()\n",
    "for ts_path in test_data_paths:\n",
    "    total_data_paths.append(ts_path)\n",
    "\n",
    "test_equ_nos=[\"YT341\", \"YT374\", \"YT377\"]\n",
    "\n",
    "for data_path in total_data_paths:\n",
    "    data = pd.read_csv(os.path.join(config.BASE_DIR, data_path))\n",
    "    equ_no = data_path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "    typ = \"train\" if equ_no not in test_equ_nos else \"test\"\n",
    "\n",
    "    \n",
    "    # all\n",
    "    data = pp.to_datetime(data, column=\"evnt_dt\")\n",
    "    data = data.set_index(\"evnt_dt\")\n",
    "    data = pp.insert_distance(data, column=\"distance\")\n",
    "    # data = pp.insert_direction(data, column=\"dir_diff\")\n",
    "\n",
    "    data[\"sin_dir\"] = data[\"direction\"].apply(math.sin)\n",
    "    data[\"cos_dir\"] = data[\"direction\"].apply(math.cos)\n",
    "    data[\"cos_dir_diff\"] = data[\"cos_dir\"].shift(1)-data[\"cos_dir\"]\n",
    "    data[\"sin_dir_diff\"] = data[\"sin_dir\"].shift(1)-data[\"sin_dir\"]\n",
    "    \n",
    "    data=data.drop(columns=[\"direction\"])\n",
    "    b=data.shape[0]\n",
    "    \n",
    "    data = data.dropna(subset=[\"distance\"], how=\"any\", axis=0); print(f\"executed type : {typ} equ_no : {equ_no} dropna(subset=distance) count : {b-data.shape[0]}\")\n",
    "    data = data.drop(columns=['reg_seq', 'altitude', 'position_fix', 'satelites', 'dev_id', 'cre_dt', 'cntr_dup', \n",
    "                            'wk_id','y_blk', 'y_bay', 'y_row', 'y_tier', 'long_cut', 'latt_cut','equ_no'], axis=1)\n",
    "    # print(data)\n",
    "    # train 추가 전처리\n",
    "    if typ == \"train\":\n",
    "        data = data[data.distance<=12]\n",
    "        data = pp.interpolate_vars(data, equ_no)\n",
    "        data = data[~((data.velocity==0) & (data.shift(1).velocity==0))] # 딱 한 번 정지 상태 외에 제거\n",
    "        train_dict[equ_no] = data.reset_index(drop=True) # 날짜 인덱스 제거\n",
    "\n",
    "    elif typ == \"test\":\n",
    "        test_dict[equ_no] = data.reset_index()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "latitude scaling complete\n",
      "longitude scaling complete\n",
      "velocity scaling complete\n",
      "distance scaling complete\n"
     ]
    }
   ],
   "source": [
    "#전체 데이터 합치기 (test에는 evnt_dt가 포함되어 있음)\n",
    "train = pd.concat([df for _, df in train_dict.items()]).reset_index(drop=True)\n",
    "test = pd.concat([df for _, df in test_dict.items()]).reset_index(drop=True)\n",
    "\n",
    "#정규화 (이상치 나름 제거 했으니 minmax로)\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    " \n",
    "target_cols=[\"latitude\", \"longitude\", \"velocity\", \"distance\"]\n",
    "scalers = [] \n",
    "for col_name in target_cols:\n",
    "    scalers.append((col_name,MinMaxScaler()))\n",
    "\n",
    "for col_name, scaler in scalers: # Scaler Fitting ( train data에 대해서만 fitting 진행 )\n",
    "    scaler.fit(train.loc[:,col_name].values.reshape(-1,1))\n",
    "    print(f\"{col_name} scaling complete\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "update dict type : train equ_no : YT301\n",
      "update dict type : train equ_no : YT303\n",
      "update dict type : train equ_no : YT308\n",
      "update dict type : train equ_no : YT312\n",
      "update dict type : train equ_no : YT313\n",
      "update dict type : train equ_no : YT324\n",
      "update dict type : train equ_no : YT340\n",
      "update dict type : train equ_no : YT343\n",
      "update dict type : train equ_no : YT366\n",
      "update dict type : train equ_no : YT375\n",
      "update dict type : train equ_no : YT389\n",
      "update dict type : train equ_no : YT391\n",
      "update dict type : train equ_no : YT396\n",
      "update dict type : test equ_no : YT341\n",
      "update dict type : test equ_no : YT374\n",
      "update dict type : test equ_no : YT377\n"
     ]
    }
   ],
   "source": [
    "w_size = 3\n",
    "p_size = 3\n",
    "\n",
    "for typ, data_dict in [(\"train\",train_dict),(\"test\",test_dict)]:\n",
    "    for equ_no, data in data_dict.items():\n",
    "        \n",
    "        for col_name, scaler in scalers: # train, test 전부 Scaling 진행\n",
    "            data[col_name] = scaler.transform(data[col_name].values.reshape(-1,1))\n",
    "    \n",
    "        X = data\n",
    "        y = data[[\"latitude\",\"longitude\"]]\n",
    "\n",
    "        X,y = pp.make_sequence_train_dataset(X, y, w_size, p_size)\n",
    "    \n",
    "        if typ == \"train\": train_dict[equ_no] = [X,y] # train dict update\n",
    "        if typ == \"test\":test_dict[equ_no] = [X,y] # test dict update\n",
    "\n",
    "        print(f\"update dict type : {typ} equ_no : {equ_no}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-138-719a81b58148>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mtest_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensorData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[0mtest_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Kimminseop\\Dropbox\\BPT GPS 예측\\2. 진행상황\\progress\\src\\preprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, x_data, y_data)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mTensorData\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 87\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_data\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#들어온 데이터를 텐서로\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     88\u001b[0m         \u001b[1;31m#self.x_data = self.x_data.permute(0,3,1,2) #이미지 개수, 채널 수, 이미지 너비, 높이\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0my_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_data\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m#들어온 데이터를 텐서로\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "X_train = np.concatenate([tr[0] for _, tr in train_dict.items()],axis=0)\n",
    "y_train = np.concatenate([tr[1] for _, tr in train_dict.items()],axis=0)\n",
    "\n",
    "X_test = np.concatenate([ts[0] for _, ts in test_dict.items()],axis=0)\n",
    "y_test = np.concatenate([ts[1] for _, ts in test_dict.items()],axis=0)\n",
    "\n",
    "utils.save_pickle(os.path.join(config.BASE_DIR, \"data\\\\train\\\\X_train_npy.pkl\"),X_train)\n",
    "utils.save_pickle(os.path.join(config.BASE_DIR, \"data\\\\train\\\\y_train_npy.pkl\"),y_train)\n",
    "utils.save_pickle(os.path.join(config.BASE_DIR, \"data\\\\test\\\\X_test_npy.pkl\"),X_test)\n",
    "utils.save_pickle(os.path.join(config.BASE_DIR, \"data\\\\test\\\\y_test_npy.pkl\"),y_test)\n",
    "\n",
    "train_data = pp.TensorData(X_train, y_train)\n",
    "train_loader = DataLoader(train_data, batch_size = 64, shuffle=False)\n",
    "\n",
    "# TimeStamp를 제외하고 DataLoader 생성\n",
    "# TimeStamp가 있었기 때문에 array의 type이 object로 잡혀있어서 바꿔주고 진행\n",
    "test_data = pp.TensorData(X_test[:,:,1:].astype(float), y_test)\n",
    "test_loader = DataLoader(test_data, batch_size = y_test.shape[0], shuffle=False)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 10/9 Loss : 0.0000743834\n",
      "Epoch : 20/19 Loss : 0.0001271139\n",
      "Epoch : 30/29 Loss : 0.0000837602\n",
      "Epoch : 40/39 Loss : 0.0000676498\n",
      "Epoch : 50/49 Loss : 0.0000610143\n",
      "Epoch : 60/59 Loss : 0.0000554614\n",
      "Epoch : 70/69 Loss : 0.0000491305\n",
      "Epoch : 80/79 Loss : 0.0000410181\n",
      "Epoch : 90/89 Loss : 0.0000301252\n",
      "Epoch : 100/99 Loss : 0.0000263106\n",
      "Epoch : 110/109 Loss : 0.0000226287\n",
      "Epoch : 120/119 Loss : 0.0000178871\n",
      "Epoch : 130/129 Loss : 0.0000166531\n",
      "Epoch : 140/139 Loss : 0.0000180913\n",
      "Epoch : 150/149 Loss : 0.0000176278\n",
      "Epoch : 160/159 Loss : 0.0000193550\n",
      "Epoch : 170/169 Loss : 0.0000152675\n",
      "Epoch : 180/179 Loss : 0.0000173307\n",
      "Epoch : 190/189 Loss : 0.0000217958\n",
      "Epoch : 200/199 Loss : 0.0000209835\n",
      "Epoch : 210/209 Loss : 0.0000221575\n",
      "Epoch : 220/219 Loss : 0.0000284142\n",
      "Epoch : 230/229 Loss : 0.0000165999\n",
      "Epoch : 240/239 Loss : 0.0000165525\n",
      "Epoch : 250/249 Loss : 0.0000134226\n",
      "Epoch : 260/259 Loss : 0.0000111713\n",
      "Epoch : 270/269 Loss : 0.0000297335\n",
      "Epoch : 280/279 Loss : 0.0000106366\n",
      "Epoch : 290/289 Loss : 0.0000135928\n",
      "Epoch : 300/299 Loss : 0.0000276821\n",
      "Epoch : 310/309 Loss : 0.0000096425\n",
      "Epoch : 320/319 Loss : 0.0000127423\n",
      "Epoch : 330/329 Loss : 0.0000218303\n",
      "Epoch : 340/339 Loss : 0.0000119356\n",
      "Epoch : 350/349 Loss : 0.0000081150\n",
      "Epoch : 360/359 Loss : 0.0000076805\n",
      "Epoch : 370/369 Loss : 0.0000085958\n",
      "Epoch : 380/379 Loss : 0.0000082925\n",
      "Epoch : 390/389 Loss : 0.0000082728\n",
      "Epoch : 400/399 Loss : 0.0000180186\n",
      "Epoch : 410/409 Loss : 0.0000188273\n",
      "Epoch : 420/419 Loss : 0.0000188810\n",
      "Epoch : 430/429 Loss : 0.0000193179\n",
      "Epoch : 440/439 Loss : 0.0000067993\n",
      "Epoch : 450/449 Loss : 0.0000102010\n",
      "Epoch : 460/459 Loss : 0.0000064003\n",
      "Epoch : 470/469 Loss : 0.0000070866\n",
      "Epoch : 480/479 Loss : 0.0000096084\n",
      "Epoch : 490/489 Loss : 0.0000065190\n",
      "Epoch : 500/499 Loss : 0.0000082685\n",
      "Epoch : 510/509 Loss : 0.0000055412\n",
      "Epoch : 520/519 Loss : 0.0000056787\n",
      "Epoch : 530/529 Loss : 0.0000048959\n",
      "Epoch : 540/539 Loss : 0.0000057816\n",
      "Epoch : 550/549 Loss : 0.0000059745\n",
      "Epoch : 560/559 Loss : 0.0000057754\n",
      "Epoch : 570/569 Loss : 0.0000056221\n",
      "Epoch : 580/579 Loss : 0.0000066001\n",
      "Epoch : 590/589 Loss : 0.0000060553\n",
      "Epoch : 600/599 Loss : 0.0000119231\n",
      "Epoch : 610/609 Loss : 0.0000163204\n",
      "Epoch : 620/619 Loss : 0.0000053650\n",
      "Epoch : 630/629 Loss : 0.0000054530\n",
      "Epoch : 640/639 Loss : 0.0000104767\n",
      "Epoch : 650/649 Loss : 0.0000049610\n",
      "Epoch : 660/659 Loss : 0.0000139209\n",
      "Epoch : 670/669 Loss : 0.0000113134\n",
      "Epoch : 680/679 Loss : 0.0000050177\n",
      "Epoch : 690/689 Loss : 0.0000047826\n",
      "Epoch : 700/699 Loss : 0.0000145624\n",
      "Epoch : 710/709 Loss : 0.0000045002\n",
      "Epoch : 720/719 Loss : 0.0000046368\n",
      "Epoch : 730/729 Loss : 0.0000040839\n",
      "Epoch : 740/739 Loss : 0.0000039150\n",
      "Epoch : 750/749 Loss : 0.0000111074\n",
      "Epoch : 760/759 Loss : 0.0000123598\n",
      "Epoch : 770/769 Loss : 0.0000057315\n",
      "Epoch : 780/779 Loss : 0.0000041591\n",
      "Epoch : 790/789 Loss : 0.0000033391\n",
      "Epoch : 800/799 Loss : 0.0000039079\n",
      "Epoch : 810/809 Loss : 0.0000060125\n",
      "Epoch : 820/819 Loss : 0.0000042789\n",
      "Epoch : 830/829 Loss : 0.0000036703\n",
      "Epoch : 840/839 Loss : 0.0000034849\n",
      "Epoch : 850/849 Loss : 0.0000035100\n",
      "Epoch : 860/859 Loss : 0.0000039966\n",
      "Epoch : 870/869 Loss : 0.0000120036\n",
      "Epoch : 880/879 Loss : 0.0000111536\n",
      "Epoch : 890/889 Loss : 0.0000031096\n",
      "Epoch : 900/899 Loss : 0.0000043386\n",
      "Epoch : 910/909 Loss : 0.0000053568\n",
      "Epoch : 920/919 Loss : 0.0000032476\n",
      "Epoch : 930/929 Loss : 0.0000065607\n",
      "Epoch : 940/939 Loss : 0.0000031346\n",
      "Epoch : 950/949 Loss : 0.0000027060\n",
      "Epoch : 960/959 Loss : 0.0000033915\n",
      "Epoch : 970/969 Loss : 0.0000053035\n",
      "Epoch : 980/979 Loss : 0.0000096250\n",
      "Epoch : 990/989 Loss : 0.0000037209\n",
      "Epoch : 1000/999 Loss : 0.0000029981\n"
     ]
    }
   ],
   "source": [
    "from src import model\n",
    "num_epoch = 1000\n",
    "hid_dim = 512\n",
    "\n",
    "in_dim = 6\n",
    "out_dim = 6\n",
    "# device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device = \"cpu\"\n",
    "m = model._LSTM2(in_dim = in_dim, hid_dim = hid_dim, out_dim = out_dim, num_layers = 1, device=device)\n",
    "\n",
    "crit = torch.nn.MSELoss()\n",
    "optimizer = optim.Adam(m.parameters(), 0.0001)\n",
    "best_rmse = 10e+10\n",
    "best_mape = 0\n",
    "\n",
    "best_loss = 99999999\n",
    "for i,epoch in enumerate(range(num_epoch)):\n",
    "    \n",
    "    for batch_idx, (X_train, y_train) in enumerate(train_loader): \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #6개 값 출력 \n",
    "        out = m.forward(X_train)\n",
    "        loss = crit(out.view(-1,6), y_train.view(-1,6))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if loss < best_loss :\n",
    "            best_loss = loss\n",
    "            torch.save(m, os.path.join(config.BASE_DIR, \"model\\\\best-model.pt\"))\n",
    "            torch.save(m.state_dict(), os.path.join(config.BASE_DIR, \"model\\\\best-model-parameters.pt\"))\n",
    "\n",
    "    i += 1\n",
    "\n",
    "    if i%10 == 0:\n",
    "        print(f\"Epoch : {i}/{epoch} Loss : {loss:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('latitude', MinMaxScaler()),\n",
       " ('longitude', MinMaxScaler()),\n",
       " ('velocity', MinMaxScaler()),\n",
       " ('direction', MinMaxScaler()),\n",
       " ('distance', MinMaxScaler()),\n",
       " ('dir_diff', MinMaxScaler())]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src import utils\n",
    "scalers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.save_pickle(os.path.join(config.BASE_DIR, \"model\\\\scalers.pkl\"), scalers)\n",
    "torch.save( m, os.path.join(config.BASE_DIR,f'model/best-model.pt') )\n",
    "torch.save( m.state_dict(), os.path.join(config.BASE_DIR, f'model/best-model-parameters.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Count : 19991\n",
      "Average Distance Diff : 2.098620653152466\n"
     ]
    }
   ],
   "source": [
    "## 모델 로드\n",
    "best_model = torch.load(os.path.join(config.BASE_DIR, 'model\\\\best-model.pt'))\n",
    "test = torch.load(os.path.join(config.BASE_DIR, \"data\\\\test\\\\test.pkl\"))\n",
    "test_loader=DataLoader(test)\n",
    "\n",
    "# Test the model\n",
    "cnt=0\n",
    "y_preds, y_trues=[],[]\n",
    "outliers=[]\n",
    "\n",
    "p_size=3\n",
    "w_size=3\n",
    "\n",
    "from src import utils\n",
    "scalers=utils.load_pickle(os.path.join(config.BASE_DIR, \"model\\\\scalers.pkl\"))\n",
    "\n",
    "lat_sclr = scalers[0]\n",
    "lon_sclr = scalers[1]\n",
    "\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total_loss = 0\n",
    "    best_loss = 999999\n",
    "    outlier_cnt=0\n",
    "    for X_test, y_true in test_loader:\n",
    "        \n",
    "        y_true = y_true.reshape((-1,2))\n",
    "        y_true = np.concatenate((lat_sclr[1].inverse_transform(y_true[:,0].reshape(-1,1)),\n",
    "                                 lon_sclr[1].inverse_transform(y_true[:,1].reshape(-1,1))),\n",
    "                                 axis=1)\n",
    "        y_true = y_true.reshape(-1, p_size*2)\n",
    "\n",
    "        y_pred=best_model(X_test)\n",
    "        y_pred=y_pred.detach().cpu().numpy()\n",
    "\n",
    "        y_pred[:,[0,2,4]] = lat_sclr[1].inverse_transform(y_pred[:,[0,2,4]])\n",
    "        y_pred[:,[1,3,5]] = lon_sclr[1].inverse_transform(y_pred[:,[1,3,5]])\n",
    "\n",
    "        loss = utils.haversine_loss(y_pred, y_true)\n",
    "        # print(loss)\n",
    "        total_loss += loss\n",
    "        y_trues.append(y_true)\n",
    "        y_preds.append(y_pred)\n",
    "        if loss < best_loss:\n",
    "            best_loss = loss\n",
    "        \n",
    "        cnt += 1\n",
    "        \n",
    "\n",
    "print(f\"Sample Count : {cnt}\")\n",
    "print(f\"Average Distance Diff : {total_loss/cnt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = utils.load_pickle(os.path.join(config.BASE_DIR, \"data\\\\test\\\\X_test_npy.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-170-8162eddd52a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 3 and the array at index 1 has size 2"
     ]
    }
   ],
   "source": [
    "np.concatenate([X_test[:,:,0],np.array(y_preds).reshape(-1,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[Timestamp('2021-10-31 19:08:51+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:52+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:53+0000', tz='UTC')]],\n",
       "\n",
       "       [[Timestamp('2021-10-31 19:08:52+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:53+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:54+0000', tz='UTC')]],\n",
       "\n",
       "       [[Timestamp('2021-10-31 19:08:53+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:54+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 19:08:55+0000', tz='UTC')]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[Timestamp('2021-10-31 20:59:52+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:53+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:54+0000', tz='UTC')]],\n",
       "\n",
       "       [[Timestamp('2021-10-31 20:59:53+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:54+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:55+0000', tz='UTC')]],\n",
       "\n",
       "       [[Timestamp('2021-10-31 20:59:54+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:55+0000', tz='UTC'),\n",
       "         Timestamp('2021-10-31 20:59:56+0000', tz='UTC')]]], dtype=object)"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[:,:,0].reshape(19991,-1,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-185-1912d0193b0f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19991\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m19991\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 1, the array at index 0 has size 1 and the array at index 1 has size 3"
     ]
    }
   ],
   "source": [
    "np.concatenate([X_test[:,:,0].reshape(19991,-1,3), np.array(y_preds).reshape(19991,3,2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19991, 3, 2)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_preds).reshape(19991,3,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 35.1094397999, 129.0949707   ],\n",
       "       [ 35.1094397999, 129.0949707   ],\n",
       "       [ 35.1094397999, 129.0949707   ],\n",
       "       ...,\n",
       "       [ 35.1076812996, 129.0941772   ],\n",
       "       [ 35.1077080003, 129.0941772   ],\n",
       "       [ 35.1077232003, 129.0941772   ]])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y_trues).reshape(-1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "302c2d6199b6f849fd8e3268cbc153a240d249ea5afee56525aaa630fbc82e46"
  },
  "kernelspec": {
   "display_name": "Python 3.6.12 ('threecall')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
